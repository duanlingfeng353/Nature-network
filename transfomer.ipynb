{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Transfomer\n",
    "\n",
    "Duan Lingfeng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-f8TnGpE_ex"
   },
   "source": [
    "Trained a  <a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">Transformer model</a>  to translate English to Chinese。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JjJJyJTZYebt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd1NWMxjfsDd"
   },
   "source": [
    "## 设置输入流水线（input pipeline）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4_Qt8W1hJE_"
   },
   "source": [
    "## Download and prepare datasets\n",
    "\n",
    "The dataset contains language translation pairs in the following format:\n",
    "\n",
    "```\n",
    "It took me three hours to do my homework.\t\n",
    "我花了3小时做作业。\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"C:/Users/Kinglake/Desktop/Bi-Microblog.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = w.rstrip().strip()\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "def en_normalizeString(s):\n",
    "    # lowercase, trim and remove non-letter characters\n",
    "    s = re.sub(r\"[^a-zA-Z0-9,.!?]+\", r\" \", s)\n",
    "    s = re.sub(r'[\" \"]+', \" \", s)\n",
    "    s = s.rstrip().strip()\n",
    "    return s\n",
    "\n",
    "def zh_normalizeString(s):\n",
    "    # lowercase, trim and remove non-letter characters\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"[^a-zA-Z0-9\\u4e00-\\u9fa5！？，。]+\", r\" \", s)\n",
    "    s = s.rstrip().strip()\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    word_pairs = []\n",
    "    j=0\n",
    "    data=open(path, encoding='UTF-8')\n",
    "    lineee=data.readline()\n",
    "    while lineee:   \n",
    "        #print(lineee)\n",
    "        w1 = lineee\n",
    "        lineee = data.readline()\n",
    "        w2 = lineee\n",
    "        lineee = data.readline()\n",
    "        word_pairs.append((en_normalizeString(w1), zh_normalizeString(w2)))\n",
    "    return word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义样本量为5000\n",
    "num_examples = 5000\n",
    "#调用上述函数，根据path_to_file中的文件，创建数组形式的数据集pairs\n",
    "pairs = create_dataset(path_to_file, num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成0~num_examples=5000的乱序数组，之后用来打乱数据集\n",
    "shuffle = np.random.permutation(num_examples)\n",
    "\n",
    "data_examples = []\n",
    "for i in range(num_examples):\n",
    "    data_examples.append('0')\n",
    "\n",
    "for i, example in enumerate(pairs):\n",
    "    data_examples[int(shuffle[i])] = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#设置训练集为4000，验证集为1000\n",
    "num_train = 4000\n",
    "num_valid = num_examples - num_train\n",
    "\n",
    "train_examples = data_examples[:num_train]\n",
    "valid_examples = data_examples[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ricky Martin At least where we live everything is in order. Sending good '\n",
      "  'vibes to everyone affected by the storm. SandyGOAWAY',\n",
      "  '至少我们住的地方还一切正常。给每个受到风暴影响的人们打打气。sandy快走吧 2小时前'),\n",
      " ('I love how she makes me feel, like anything s possible, or like life is '\n",
      "  'worth it.',\n",
      "  '我喜欢她给我带来的感觉，就像是一切都有可能，亦或是这辈子是值得的'),\n",
      " ('Oliver Trevena Shawn enjoying the ride! my legs hurt',\n",
      "  'oliver trevena shawn正在享受骑马的乐趣！ 我的腿痛'),\n",
      " ('Damn! Forgot my red button. RECorders at the Bowl, forgive me.',\n",
      "  '靠 忘了红钮了。recorders在圆形剧场， 原谅我吧。'),\n",
      " ('So if the share price rises and the dividend does not, then the yield '\n",
      "  'falls.',\n",
      "  '因此，如果股份上涨而股息不变，收益就下跌。'),\n",
      " ('Sleeping without a dream makes us feel empty.Maybe the only way to console '\n",
      "  'us is having a warm quilt and an unknown dream.Good night.',\n",
      "  '也许只有夜晚一床温暖的棉被和一个好梦，才可以慰藉每天有太多不如意的我们。'),\n",
      " ('There is no rehearsal in the life , once missing , it will be lost forever.',\n",
      "  '世界上没有破镜重圆之说，一旦失去，就意味着永远失去'),\n",
      " ('Friendship may, and often does, grow into love, but love never subsides '\n",
      "  'into friendship.',\n",
      "  '友谊可能而且常常发展成为爱情，而爱情决不会降为友谊。'),\n",
      " ('This is not where we wanted to be, and it s not where we deserve to be.',\n",
      "  '就这样结束，不是我们所想要的，也不是我们应得的'),\n",
      " ('The iPad 3 is definitely going to launch early March. There is still a '\n",
      "  'strong rumor that it will be announced January 24, which is Steve Jobs '\n",
      "  'birthday. This version will be a category killer with a quad core '\n",
      "  'processor, double the screen resolution and upgraded software!!!',\n",
      "  '3一定会在3月初上市。之前一个谣言说是1月24日，那是因为那天是steve jobs的生日。这个版本将是一个有四核心处理器的 分类商店 '\n",
      "  '，屏幕分辨率翻倍，软件也进行了升级')]\n"
     ]
    }
   ],
   "source": [
    "pprint(train_examples[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.string)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples = tf.data.Dataset.from_tensor_slices((\n",
    "    [en for en, _ in train_examples], [zh for _, zh in train_examples]\n",
    "))\n",
    "train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.string)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_examples = tf.data.Dataset.from_tensor_slices((\n",
    "    [en for en, _ in valid_examples], [zh for _, zh in valid_examples]\n",
    "))\n",
    "valid_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCEKotqosGfq"
   },
   "source": [
    "从训练数据集创建自定义子词分词器（subwords tokenizer）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "KVBg5Q8tBk5z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for en, zh in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_zh = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (zh.numpy() for en, zh in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "4DYWukNFkGQN",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [2955, 1652, 3891, 7, 975, 8845]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9KJWJjrsZ4Y"
   },
   "source": [
    "如果单词不在词典中，则分词器（tokenizer）通过将单词分解为子词来对字符串进行编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "bf2ntBxjkqK6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2955 ----> Tra\n",
      "1652 ----> ns\n",
      "3891 ----> former \n",
      "7 ----> is \n",
      "975 ----> awesome\n",
      "8845 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [29, 1890, 603, 277, 3313, 286, 1481, 8332, 8253, 8255, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "sample_string = '我的笔记本电脑发生故障了。'\n",
    "\n",
    "tokenized_string = tokenizer_zh.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original string: 我的笔记本电脑发生故障了。\n"
     ]
    }
   ],
   "source": [
    "original_string = tokenizer_zh.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 ----> 我的\n",
      "1890 ----> 笔\n",
      "603 ----> 记\n",
      "277 ----> 本\n",
      "3313 ----> 电脑\n",
      "286 ----> 发生\n",
      "1481 ----> 故\n",
      "8332 ----> �\n",
      "8253 ----> �\n",
      "8255 ----> �\n",
      "4 ----> 了\n",
      "2 ----> 。\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_zh.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "bcRp7VcQ5m6g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 2000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGi4PoVakxdc"
   },
   "source": [
    "将开始和结束标记（token）添加到输入和目标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "UZwnPr4R055s",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "  lang1 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang1.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "\n",
    "  lang2 = [tokenizer_zh.vocab_size] + tokenizer_zh.encode(\n",
    "      lang2.numpy()) + [tokenizer_zh.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JrGp5Gek6Ql"
   },
   "source": [
    "Note：为了使本示例较小且相对较快，删除长度大于40个标记的样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "2QEgbjntk6Yf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "c081xPGv1CPI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tx1sFbR-9fRs"
   },
   "source": [
    "`.map()` 内部的操作以图模式（graph mode）运行，`.map()` 接收一个不具有 numpy 属性的图张量（graph tensor）。该`分词器（tokenizer）`需要将一个字符串或 Unicode 符号，编码成整数。因此，您需要在 `tf.py_function` 内部运行编码过程，`tf.py_function` 接收一个 eager 张量，该 eager 张量有一个包含字符串值的 numpy 属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "Mah1cS-P70Iz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tf_encode(en, zh):\n",
    "  result_en, result_zh = tf.py_function(encode, [en, zh], [tf.int64, tf.int64])\n",
    "  result_en.set_shape([None])\n",
    "  result_zh.set_shape([None])\n",
    "\n",
    "  return result_en, result_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "9mk9AZdZ5bcS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# 将数据集缓存到内存中以加快读取速度。\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "valid_dataset = valid_examples.map(tf_encode)\n",
    "valid_dataset = valid_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "_fXvfYVfQr2n",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 52), dtype=int64, numpy=\n",
       " array([[9055,   60, 1777, ...,    0,    0,    0],\n",
       "        [9055,   60,  252, ...,    0,    0,    0],\n",
       "        [9055,   10,  436, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [9055,   23, 3513, ...,    0,    0,    0],\n",
       "        [9055,  157, 1188, ...,    0,    0,    0],\n",
       "        [9055,   23, 7468, ...,    0,    0,    0]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(64, 57), dtype=int64, numpy=\n",
       " array([[8355, 2133,  257, ...,    0,    0,    0],\n",
       "        [8355,  128, 6936, ...,    0,    0,    0],\n",
       "        [8355,    8,   47, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8355,   10,  172, ...,    0,    0,    0],\n",
       "        [8355, 2487, 2492, ...,    0,    0,    0],\n",
       "        [8355, 1957, 5729, ...,    0,    0,    0]], dtype=int64)>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_batch, zh_batch = next(iter(valid_dataset))\n",
    "en_batch, zh_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBQuibYA4n0n"
   },
   "source": [
    "## 位置编码（Positional encoding）\n",
    "\n",
    "因为该模型并不包括任何的循环（recurrence）或卷积，所以模型添加了位置编码，为模型提供一些关于单词在句子中相对位置的信息。\n",
    "\n",
    "位置编码向量被加到嵌入（embedding）向量中。嵌入表示一个 d 维空间的标记，在 d 维空间中有着相似含义的标记会离彼此更近。但是，嵌入并没有对在一句话中的词的相对位置进行编码。因此，当加上位置编码后，词将基于*它们含义的相似度以及它们在句子中的位置*，在 d 维空间中离彼此更近。\n",
    "\n",
    "计算位置编码的公式如下：\n",
    "\n",
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "WhIOZjMNKujn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "1Rz82wEs5biZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # 将 sin 应用于数组中的偶数索引（indices）；2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # 将 cos 应用于数组中的奇数索引；2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "1kLCla68EloE",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_b4ou4TYqUN"
   },
   "source": [
    "## 遮挡（Masking）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s42Uydjkv0hF"
   },
   "source": [
    "遮挡一批序列中所有的填充标记（pad tokens）。这确保了模型不会将填充作为输入。该 mask 表明填充值 `0` 出现的位置：在这些位置 mask 输出 `1`，否则输出 `0`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "U2i8-e1s8ti9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # 添加额外的维度来将填充加到\n",
    "  # 注意力对数（logits）。\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "A7BYeBCNvi7n",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0hzukDBgVom"
   },
   "source": [
    "前瞻遮挡（look-ahead mask）用于遮挡一个序列中的后续标记（future tokens）。换句话说，该 mask 表明了不应该使用的条目。\n",
    "\n",
    "这意味着要预测第三个词，将仅使用第一个和第二个词。与此类似，预测第四个词，仅使用第一个，第二个和第三个词，依此类推。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "dVxS8OPI9uI0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "yxKGuXxaBeeE",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xluDl5cXYy4y"
   },
   "source": [
    "## 按比缩放的点积注意力（Scaled dot product attention）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "LazzUq3bJ5SH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"计算注意力权重。\n",
    "  q, k, v 必须具有匹配的前置维度。\n",
    "  k, v 必须有匹配的倒数第二个维度，例如：seq_len_k = seq_len_v。\n",
    "  虽然 mask 根据其类型（填充或前瞻）有不同的形状，\n",
    "  但是 mask 必须能进行广播转换以便求和。\n",
    "  \n",
    "  参数:\n",
    "    q: 请求的形状 == (..., seq_len_q, depth)\n",
    "    k: 主键的形状 == (..., seq_len_k, depth)\n",
    "    v: 数值的形状 == (..., seq_len_v, depth_v)\n",
    "    mask: Float 张量，其形状能转换成\n",
    "          (..., seq_len_q, seq_len_k)。默认为None。\n",
    "    \n",
    "  返回值:\n",
    "    输出，注意力权重\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # 缩放 matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # 将 mask 加入到缩放的张量上。\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax 在最后一个轴（seq_len_k）上归一化，因此分数\n",
    "  # 相加等于1。\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiqETnhCkoXh"
   },
   "source": [
    "当 softmax 在 K 上进行归一化后，它的值决定了分配到 Q 的重要程度。\n",
    "\n",
    "输出表示注意力权重和 V（数值）向量的乘积。这确保了要关注的词保持原样，而无关的词将被清除掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "n90YjClyInFy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "yAzUAf2DPlNt",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# 这条 `请求（query）符合第二个`主键（key）`，\n",
    "# 因此返回了第二个`数值（value）`。\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "zg6k-fGhgXra",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 这条请求符合重复出现的主键（第三第四个），\n",
    "# 因此，对所有的相关数值取了平均。\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "UAq3YOzUgXhb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 这条请求符合第一和第二条主键，\n",
    "# 因此，对它们的数值去了平均。\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOz-4_XIhaTP"
   },
   "source": [
    "将所有请求一起*传递*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "6dlU8Tm-hYrF",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmzGPEy64qmA"
   },
   "source": [
    "## 多头注意力（Multi-head attention）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "BSV3PPKsYecw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"分拆最后一个维度到 (num_heads, depth).\n",
    "    转置结果使得形状为 (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D8FJue5lDyZ"
   },
   "source": [
    "创建一个 `MultiHeadAttention` 层进行尝试。在序列中的每个位置 `y`，`MultiHeadAttention` 在序列中的所有其他位置运行所有8个注意力头，在每个位置y，返回一个新的同样长度的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "Hu94p-_-2_BX",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## 点式前馈网络（Point wise feed forward network）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBqzJXGfHK3X"
   },
   "source": [
    "点式前馈网络由两层全联接层组成，两层之间有一个 ReLU 激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "ET7xLt0yCT6Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "mytb1lPyOHLB",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## 编码与解码（Encoder and decoder）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfYJG-Kvgwy2"
   },
   "source": [
    "Transformer 模型与标准的[具有注意力机制的序列到序列模型（sequence to sequence with attention model）](nmt_with_attention.ipynb)，遵循相同的一般模式。\n",
    "\n",
    "* 输入语句经过 `N` 个编码器层，为序列中的每个词/标记生成一个输出。\n",
    "* 解码器关注编码器的输出以及它自身的输入（自注意力）来预测下一个词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFv-FNYUmvpn"
   },
   "source": [
    "### 编码器层（Encoder layer）\n",
    "\n",
    "每个编码器层包括以下子层：\n",
    "\n",
    "1.   多头注意力（有填充遮挡）\n",
    "2.   点式前馈网络（Point wise feed forward networks）。\n",
    "\n",
    "每个子层在其周围有一个残差连接，然后进行层归一化。残差连接有助于避免深度网络中的梯度消失问题。\n",
    "\n",
    "每个子层的输出是 `LayerNorm(x + Sublayer(x))`。归一化是在 `d_model`（最后一个）维度完成的。Transformer 中有 N 个编码器层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "ncyS-Ms3i2x_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "AzZRXdO0mI48",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### 解码器层（Decoder layer）\n",
    "\n",
    "每个解码器层包括以下子层：\n",
    "\n",
    "1.   遮挡的多头注意力（前瞻遮挡和填充遮挡）\n",
    "2.   多头注意力（用填充遮挡）。V（数值）和 K（主键）接收*编码器输出*作为输入。Q（请求）接收*遮挡的多头注意力子层的输出*。\n",
    "3.   点式前馈网络\n",
    "\n",
    "每个子层在其周围有一个残差连接，然后进行层归一化。每个子层的输出是 `LayerNorm(x + Sublayer(x))`。归一化是在 `d_model`（最后一个）维度完成的。\n",
    "\n",
    "Transformer 中共有 N 个解码器层。\n",
    "\n",
    "当 Q 接收到解码器的第一个注意力块的输出，并且 K 接收到编码器的输出时，注意力权重表示根据编码器的输出赋予解码器输入的重要性。换一种说法，解码器通过查看编码器输出和对其自身输出的自注意力，预测下一个词。参看按比缩放的点积注意力部分的演示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "9SoX0-vd1hue",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "Ne2Bqx8k71l0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### 编码器（Encoder）\n",
    "\n",
    "`编码器` 包括：\n",
    "1.   输入嵌入（Input Embedding）\n",
    "2.   位置编码（Positional Encoding）\n",
    "3.   N 个编码器层（encoder layers）\n",
    "\n",
    "输入经过嵌入（embedding）后，该嵌入与位置编码相加。该加法结果的输出是编码器层的输入。编码器的输出是解码器的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "jpEox7gJ8FCI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # 将嵌入和位置编码相加。\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "8QG9nueFQKXx",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "\n",
    "sample_encoder_output = sample_encoder(tf.random.uniform((64, 62)), \n",
    "                                       training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### 解码器（Decoder）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtT7PKzrXkNr"
   },
   "source": [
    "`解码器`包括：\n",
    "1.   输出嵌入（Output Embedding）\n",
    "2.   位置编码（Positional Encoding）\n",
    "3.   N 个解码器层（decoder layers）\n",
    "\n",
    "目标（target）经过一个嵌入后，该嵌入和位置编码相加。该加法结果是解码器层的输入。解码器的输出是最后的线性层的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "d5_d5-PLQXwY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "a1jXoAMRZyvu",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "\n",
    "output, attn = sample_decoder(tf.random.uniform((64, 26)), \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False, look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## 创建 Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer 包括编码器，解码器和最后的线性层。解码器的输出是线性层的输入，返回线性层的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "PED3bIpOYkBu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "tJ4fbQcIkHW1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 26, 8000])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 62))\n",
    "temp_target = tf.random.uniform((64, 26))\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## 配置超参数（hyperparameters）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "为了让本示例小且相对较快，已经减小了*num_layers、 d_model 和  dff* 的值。 \n",
    "\n",
    "Transformer 的基础模型使用的数值为：*num_layers=6*，*d_model = 512*，*dff = 2048*。关于所有其他版本的 Transformer，请查阅[论文](https://arxiv.org/abs/1706.03762)。\n",
    "\n",
    "Note：通过改变以下数值，您可以获得在许多任务上达到最先进水平的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "lnJn5SLA2ahP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_en.vocab_size + 2\n",
    "target_vocab_size = tokenizer_zh.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9057"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8357"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## 优化器（Optimizer）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOmWW--yP3zx"
   },
   "source": [
    "根据[论文](https://arxiv.org/abs/1706.03762)中的公式，将 Adam 优化器与自定义的学习速率调度程序（scheduler）配合使用。\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "iYQdOO1axwEI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "7r4scdulztRx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "f33ZCgvHpPdG",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## 损失函数与指标（Loss and metrics）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "由于目标序列是填充（padded）过的，因此在计算损失函数时，应用填充遮挡非常重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "MlhsJMm0TW_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "67oqVHiT0Eiu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "phlyxMnm-Tpx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## 训练与检查点（Training and checkpointing）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "UiysUa--4tOU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "ZOJUSB1T8GjM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # 编码器填充遮挡\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # 在解码器的第二个注意力模块使用。\n",
    "  # 该填充遮挡用于遮挡编码器的输出。\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # 在解码器的第一个注意力模块使用。\n",
    "  # 用于填充（pad）和遮挡（mask）解码器获取到的输入的后续标记（future tokens）。\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "创建检查点的路径和检查点管理器（manager）。这将用于在每 `n` 个周期（epochs）保存检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "hNhuYfllndLZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 如果检查点存在，则恢复最新的检查点。\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Di_Yaa1gf9r"
   },
   "source": [
    "目标（target）被分成了 tar_inp 和 tar_real。tar_inp 作为输入传递到解码器。`tar_real` 是位移了 1 的同一个输入：在 `tar_inp` 中的每个位置，`tar_real` 包含了应该被预测到的下一个标记（token）。\n",
    "\n",
    "例如，`sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "Transformer 是一个自回归（auto-regressive）模型：它一次作一个部分的预测，然后使用到目前为止的自身的输出来决定下一步要做什么。\n",
    "\n",
    "在训练过程中，本示例使用了 teacher-forcing 的方法（就像[文本生成教程](./text_generation.ipynb)中一样）。无论模型在当前时间步骤下预测出什么，teacher-forcing 方法都会将真实的输出传递到下一个时间步骤上。\n",
    "\n",
    "当 transformer 预测每个词时，*自注意力（self-attention）*功能使它能够查看输入序列中前面的单词，从而更好地预测下一个单词。\n",
    "\n",
    "为了防止模型在期望的输出上达到峰值，模型使用了前瞻遮挡（look-ahead mask）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "LKpoA6q1sJFj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "iJwmp9OE29oj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 该 @tf.function 将追踪-编译 train_step 到 TF 图中，以便更快地\n",
    "# 执行。该函数专用于参数张量的精确形状。为了避免由于可变序列长度或可变\n",
    "# 批次大小（最后一批次较小）导致的再追踪，使用 input_signature 指定\n",
    "# 更多的通用形状。\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM2PDWGDJ_8V"
   },
   "source": [
    "英语作为输入语言，中文为目标语言。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "bbvmaKNiznHZ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.3902 Accuracy 0.0003\n",
      "Epoch 1 Batch 50 Loss 3.9326 Accuracy 0.0053\n",
      "Epoch 1 Loss 3.9169 Accuracy 0.0077\n",
      "Time taken for 1 epoch: 36.97373652458191 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 4.3715 Accuracy 0.0219\n",
      "Epoch 2 Batch 50 Loss 3.7939 Accuracy 0.0239\n",
      "Epoch 2 Loss 3.8086 Accuracy 0.0240\n",
      "Time taken for 1 epoch: 18.661856412887573 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 3.7004 Accuracy 0.0248\n",
      "Epoch 3 Batch 50 Loss 3.7118 Accuracy 0.0272\n",
      "Epoch 3 Loss 3.7423 Accuracy 0.0279\n",
      "Time taken for 1 epoch: 18.77178406715393 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 4.2341 Accuracy 0.0366\n",
      "Epoch 4 Batch 50 Loss 3.6547 Accuracy 0.0340\n",
      "Epoch 4 Loss 3.6836 Accuracy 0.0347\n",
      "Time taken for 1 epoch: 18.514002084732056 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 3.3094 Accuracy 0.0315\n",
      "Epoch 5 Batch 50 Loss 3.5993 Accuracy 0.0388\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-1\n",
      "Epoch 5 Loss 3.6259 Accuracy 0.0396\n",
      "Time taken for 1 epoch: 19.75354266166687 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 4.0160 Accuracy 0.0506\n",
      "Epoch 6 Batch 50 Loss 3.4613 Accuracy 0.0417\n",
      "Epoch 6 Loss 3.4620 Accuracy 0.0418\n",
      "Time taken for 1 epoch: 18.744133472442627 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 3.1974 Accuracy 0.0379\n",
      "Epoch 7 Batch 50 Loss 3.3322 Accuracy 0.0444\n",
      "Epoch 7 Loss 3.3337 Accuracy 0.0446\n",
      "Time taken for 1 epoch: 18.797702312469482 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 3.4099 Accuracy 0.0451\n",
      "Epoch 8 Batch 50 Loss 3.2447 Accuracy 0.0466\n",
      "Epoch 8 Loss 3.2598 Accuracy 0.0468\n",
      "Time taken for 1 epoch: 18.84561586380005 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 3.3800 Accuracy 0.0526\n",
      "Epoch 9 Batch 50 Loss 3.1827 Accuracy 0.0482\n",
      "Epoch 9 Loss 3.2351 Accuracy 0.0491\n",
      "Time taken for 1 epoch: 18.590874671936035 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 3.7001 Accuracy 0.0611\n",
      "Epoch 10 Batch 50 Loss 3.1487 Accuracy 0.0501\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train\\ckpt-2\n",
      "Epoch 10 Loss 3.1669 Accuracy 0.0508\n",
      "Time taken for 1 epoch: 19.567861080169678 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 3.1625 Accuracy 0.0482\n",
      "Epoch 11 Batch 50 Loss 3.1686 Accuracy 0.0532\n",
      "Epoch 11 Loss 3.1638 Accuracy 0.0531\n",
      "Time taken for 1 epoch: 18.883747100830078 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 3.1575 Accuracy 0.0622\n",
      "Epoch 12 Batch 50 Loss 3.0976 Accuracy 0.0551\n",
      "Epoch 12 Loss 3.0950 Accuracy 0.0550\n",
      "Time taken for 1 epoch: 18.58169913291931 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 3.5474 Accuracy 0.0670\n",
      "Epoch 13 Batch 50 Loss 3.1162 Accuracy 0.0576\n",
      "Epoch 13 Loss 3.1153 Accuracy 0.0573\n",
      "Time taken for 1 epoch: 18.05364203453064 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 2.5703 Accuracy 0.0479\n",
      "Epoch 14 Batch 50 Loss 2.9528 Accuracy 0.0564\n",
      "Epoch 14 Loss 2.9944 Accuracy 0.0571\n",
      "Time taken for 1 epoch: 18.249107360839844 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 2.8844 Accuracy 0.0466\n",
      "Epoch 15 Batch 50 Loss 2.9101 Accuracy 0.0575\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train\\ckpt-3\n",
      "Epoch 15 Loss 2.9046 Accuracy 0.0574\n",
      "Time taken for 1 epoch: 19.269879579544067 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 2.9072 Accuracy 0.0548\n",
      "Epoch 16 Batch 50 Loss 2.9171 Accuracy 0.0600\n",
      "Epoch 16 Loss 2.9378 Accuracy 0.0608\n",
      "Time taken for 1 epoch: 18.00556492805481 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 2.5827 Accuracy 0.0575\n",
      "Epoch 17 Batch 50 Loss 2.8808 Accuracy 0.0611\n",
      "Epoch 17 Loss 2.8862 Accuracy 0.0613\n",
      "Time taken for 1 epoch: 18.124701499938965 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 2.3587 Accuracy 0.0502\n",
      "Epoch 18 Batch 50 Loss 2.8330 Accuracy 0.0629\n",
      "Epoch 18 Loss 2.8471 Accuracy 0.0631\n",
      "Time taken for 1 epoch: 17.97005009651184 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 2.8975 Accuracy 0.0656\n",
      "Epoch 19 Batch 50 Loss 2.7081 Accuracy 0.0622\n",
      "Epoch 19 Loss 2.7163 Accuracy 0.0626\n",
      "Time taken for 1 epoch: 18.358095407485962 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 2.4247 Accuracy 0.0575\n",
      "Epoch 20 Batch 50 Loss 2.7473 Accuracy 0.0658\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train\\ckpt-4\n",
      "Epoch 20 Loss 2.7388 Accuracy 0.0655\n",
      "Time taken for 1 epoch: 18.912270069122314 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## 评估（Evaluate）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6APsFrgImLW"
   },
   "source": [
    "以下步骤用于评估：\n",
    "\n",
    "* 用英语分词器（`tokenizer_en`）编码输入语句。此外，添加开始和结束标记，这样输入就与模型训练的内容相同。这是编码器输入。\n",
    "* 解码器输入为 `start token == tokenizer_en.vocab_size`。\n",
    "* 计算填充遮挡和前瞻遮挡。\n",
    "* `解码器`通过查看`编码器输出`和它自身的输出（自注意力）给出预测。\n",
    "* 选择最后一个词并计算它的 argmax。\n",
    "* 将预测的词连接到解码器输入，然后传递给解码器。\n",
    "* 在这种方法中，解码器根据它预测的之前的词预测下一个。\n",
    "\n",
    "Note：这里使用的模型具有较小的能力以保持相对较快，因此预测可能不太正确。要复现论文中的结果，请使用全部数据集，并通过修改上述超参数来使用基础 transformer 模型或者 transformer XL。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "5buvMlnvyrFm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_en.vocab_size]\n",
    "  end_token = [tokenizer_en.vocab_size + 1]\n",
    "  \n",
    "  # 输入语句是葡萄牙语，增加开始和结束标记\n",
    "  inp_sentence = start_token + tokenizer_en.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # 因为目标是英语，输入 transformer 的第一个词应该是\n",
    "  # 英语的开始标记。\n",
    "  decoder_input = [tokenizer_zh.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # 从 seq_len 维度选择最后一个词\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # 如果 predicted_id 等于结束标记，就返回结果\n",
    "    if predicted_id == tokenizer_zh.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # 连接 predicted_id 与输出，作为解码器的输入传递到解码器。\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "CN-BV43FMBej",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = tokenizer_zh.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # 画出注意力权重\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_en.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_zh.decode([i]) for i in result \n",
    "                        if i < tokenizer_zh.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "lU2_yG_vBGza",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_zh.decode([i for i in result \n",
    "                                            if i < tokenizer_zh.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "YsxrAlvFG8SZ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: We must cancel our trip to Japan.\n",
      "Predicted translation: 我们我们是新的的人在其的。\n",
      "Real translation: 我们必须取消我们去日本的旅行。\n"
     ]
    }
   ],
   "source": [
    "translate(\"We must cancel our trip to Japan.\")\n",
    "print (\"Real translation: 我们必须取消我们去日本的旅行。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "7EH5y_aqI4t1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: We have almost finished our work.\n",
      "Predicted translation: 在在在在在在在在在在在了。\n",
      "Real translation: 我们几乎完成了我们的工作。\n"
     ]
    }
   ],
   "source": [
    "translate(\"We have almost finished our work.\")\n",
    "print (\"Real translation: 我们几乎完成了我们的工作。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "J-hVCTSUMlkb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Even though I studied English for 6 years in school, I'm not good at speaking it.\n",
      "Predicted translation: 我在在在在在在到 在主 我表演，我呢\n",
      "Real translation: 尽管我在学校学了6年英语，我还是说不好。\n"
     ]
    }
   ],
   "source": [
    "translate(\"Even though I studied English for 6 years in school, I'm not good at speaking it.\")\n",
    "print (\"Real translation: 尽管我在学校学了6年英语，我还是说不好。\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "s_qNSzzyaCbD"
   ],
   "name": "transformer.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}